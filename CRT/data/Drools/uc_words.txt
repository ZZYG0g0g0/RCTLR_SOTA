Currently , when summing longs in an accumulate , we get something like this : when ... $ t : Number ( ... ) from accumulate ( ... , sum ( $ p.getLongWeight ( ) ) ) then scoreHolder.addHard ( $ t.longValue ( ) ) ; This has 3 problems : Loss of precision : the long sum ` 1881617265586265321L ` will incorrectly return ` 1.88161726558626534E18 ` , so ` 13 ` too much ! The BigDecimal sum of ` 0.09 ` and ` 0.01 ` will also be incorrect . Loss of performance : Summing with a Double total is significantly slower than summing with a Long total or an Integer total . Example complexity ( minor , not all of us agree on this argument ) : the use of ` Number ` is an abstraction that doesn t bring any value to the use case . It s worthless complexity . Solution proposal A ) for 7.0 as discussed with Mario : Based on the argument type to the sum function , the compiler selects a different sum function implementation . This is similar to java overloading mechanism , where ` System.out.println ( 1 ) ` selects a different method implementation than ` System.out.println ( 2.0 ) ` . Support sum ( Long ) : when ... $ t : Long ( ... ) from accumulate ( ... , sum ( $ p.getLongWeight ( ) ) ) then scoreHolder.addHard ( $ t ) ; and sum ( BigDecimal ) : when ... $ t : BigDecimal ( ... ) from accumulate ( ... , sum ( $ p.getBigDecimalWeight ( ) ) ) then scoreHolder.addHard ( $ t ) ; and also support sum ( Integer ) and sum ( BigInteger ) . If this works well , we can consider it for other functions as well in a different jira issue . Special case 1 : sum ( Number ) should default to sum ( Double ) for backwards compatibility . when ... $ t : Number ( ... ) from accumulate ( ... , sum ( $ p.getNumberWeight ( ) ) ) then scoreHolder.addHard ( $ t.doubleValue ( ) ) ; Not-so-special case 2 : to sum integers into a long total , the user should just use : $ t : Long ( ... ) from accumulate ( ... , sum ( ( long ) $ p.getIntWeight ( ) ) ) 
Configuration is very lightweight , but it prevents interoperability , so we have migrated to the heaver DOM Element for XML fragments . 
Using a different PackageBuilder per namespace is a pita . 
Attaching a RuleBase to a packagebuilder allows for a more shell like environment . 
The current action framework allows an action to be specified for an action node . However , actions could be added to other locations as well , such as on-entry and on-exit actions on nodes , etc . The action framework should be generalized to support these kinds of actions as well . 
Allow direct property access to pattern bound variables Allow the usage of direct property access for pattern bound variables . Example : rule test auto bindings 1 when $ p : Person ( ) ; $ c : Cheese ( type == $ p.likes , price == $ c.price ) then results.add ( $ p ) ; end 
The xml format should support variables and parameters using different data types like boolean , integer , object , list , etc . 
We need to reset all the memories in the working memory , without doing cancellation events . 
Add fault node and exception handlers to process and composite context node , in core , XML and IDE 
Start nodes can be automatically triggered , e.g . when rules are activated or when an event is signalled . 
Processes could listen to external events ( e.g . using an event node of type external ) , where the process instances are automatically notified ( using some kind of event correlation ) when the event occurs . 
As discussed in the Drools boot camp , add support to rules metadata : rule xyz @ foo ( bar ) @ foo2 ( bar2 ) when end 
As discussed in drools boot camp , add support to expressions in enabled rule attribute . 
added Extends keyword to DRL grammar . When a rule extends another , it will pull the entire LHS from its parent , to the current rule before execution . An example : rule test rule 1 enabled false when c : Cheese ( type == stilton ) then list.add ( new String ( rule 1 ) ) ; end rule test rule 2 extends test rule 1 enabled false when Cheese ( price & lt ; = 6.00 ) from c then list.add ( new String ( rule 2 ) ) ; end rule test rule 3 extends test rule 2 when Cheese ( price & gt ; 1.00 ) from c then list.add ( new String ( rule 3 ) ) ; end Test is in MiscTest.java 
Temporal operators must be fixed and documented . Also , add support to time units parsing . 
An XML file with contains a composition of resources should be supported , so kbases can be built via configuration and not always programmatically . 
Update wizards support debugging of new session etc . 
Allow configuration of which node types can be used in the graphical editor . 
Add jess style accumulate functionality . 
instance equal cross products should be removed . 
Add support to fact expiration , change expiration offset to take into account not only session clock current time but also the actual event timestamp . 
The history log should not only log information about the execution of process instances but also allow the logging of all node instance information in the database . 
Currently there exists the method getWorkingMemoryEntryPoint ( String ) - that will return the named entry point . There is not an API call exposed to allow the collection of entry points to be gathered . Such as Collection & lt ; WorkingMemoryEntryPoint & gt ; getWorkingMemoryEntryPoints ( ) This would be useful in many ways to allow developers to maintain entry points and list those points for further use ( IE a gui that tests rules by allowing the selection of which entry point an event enters ) Otherwise the developer is forced to hold and sync this information outside the drools code , which is both messy and prone to bugs and faults . A typical way would be to hold a list of entry points at their creation and hope that no other code removes the entry point without updating the list . Discussed with e tirelli on IRC . 
A convinient helper function to schedule rule executions in a similar manner to the cron utility would be useful . My specific use case is for a long running session to periodically write out data to a persistence store ( db , file , etc ) The current code for this is as follows : rule DBpoll duration ( 30s ) when $ d : String ( toString== Run ) then System.out.println ( 30seconds elapsed ) ; Database.dosomething ( ) ; modify ( $ d ) { } ; end -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- session.insert ( new String ( Run ) ) ; -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - While this method does work , it requires the external dummy object trigger . In dynamically generated rules and rules pulled in from libraries , etc ( not under the current developers control ) it is difficult to ensure that a suibtable trigger is available . Therefore a cron like function would solve this issue . I envision the EVERY keyword and possibly a COUNT or for loop style format rule DBpoll EVERY ( 30s , 100 ) & lt ; -- means every 30 seconds for 100 iterations . or EVERY ( 30s , 10m ) & lt ; -- every 30 seconds for 10 mins then System.out.println ( 30seconds elapsed ) ; Database.dosomething ( ) ; end 
Add a tag for facts with property change support : declare MyFact @ propertyChangeSupport end 
It is often desirable for every execute to be executed against the latest KnowledgeBase , so the session needs to be agent aware and always check the agent for the latest kbase . 
Any chance we can get some performance improvement by replacing all uses of StringBuffer in org.drools.util.StringUtils with StringBuilder ? If the minimum JVM version for drools is 1.5 StringBuilder is more efficient than StringBuffer for all the current uses in this code . From the javadocs : This class is designed for use as a drop-in replacement for StringBuffer in places where the string buffer was being used by a single thread ( as is generally the case ) 
Support for StateNode for Finite State Machines 
An ad-hoc or dynamic node acts as a node container where not all nodes are cleanly connected to each other but they are modeled as separate fragments that are not necessarily linked to each other . By default , all nodes that do not have an incoming connection would be triggered when the dynamic node is triggered , and the node will wait until all node instances have been completed before continuing . Different strategies could also allow : ( rule or code ) constriants that define when certain fragments should be activated the user can add additional node instances at runtime , even though they are not modeled as part of the process , and the node will wait until they are completed as well 
New APIs for Drools Grid 
Add forall Conditional Element 
We do a lot of hard coding to ClassObjectType . We need to refactor this to make it generic so we can work with jess/clips style Templates . 
The knowledge agent uses UrlResource - which is fine for http and https - except when network is down . Would be nice to cache the resource so that it can use a last known good version . 
Add JMX support to enable monitoring of existing instances . 
QueryResult should wrap the returned list and the used working memory and provide a conveinience API to working with the result list . 
Nice new feature from Bill Tarr to generate rules from a JDBC result set - very simple to use . 
Hello , I am trying to determine , iterate the working memory streams within my rule by doing the following : for ( WorkingMemoryEntryPoint entry : session.getWorkingMemoryEntryPoints ( ) ) { System.err.println ( entry point stream : + entry.toString ( ) ) ; } But I can find no method/way to finid the actual text name of the entry point ( what is written in the rule as from entry-point xxxx ) . Is there a way to do this ? To list the readable names of the entry points from your session ? I would like to list those entry points in a drop down as application profiles , so if they have one selected , one entry point of rules will be inserted to and so on .. Thanks , Chris 
User might want to use verifier to validate rules with his own rules 
Using a listener approach does not work in combination with persistence ( as process instances that are currently not loaded will not be notified ) . Using a signal approach will automatically reload the necessary process instances . 
Drools Grid implementation for lightweight and distributed environments . Version 2 . 
Create a simple framework to gather data and generate reports about a session . This is useful for debugging purposes . 
Better reporting of what were the components that caused the verifier message ( Error / Warning / Note ) . If the causes have causes for example redundancy that depends of some subsumptions create a tree of causes . 
Allow for multiple named consequences , which can be used for branch conditional elements . 
Refactoring of the VSM APIs to the new Semantic for Local/Remote/Grid Environments . 
Unique path is better since it contains the exact path to the component . This can later be used for refactoring or to highlight the peace of rule that caused the problem . 
When RuleBuilder instantiates the type resolver add an entry for dynamic imports of the current package namaspace . 
Expose org.drools.runtime.rule StatefulRuleSession . fireAllRules ( org.drools.runtime.rule . AgendaFilter agendaFilter , int fireLimit ) fireAllRules ( AgendaFilter agendaFilter , int fireLimit ) is exposed in org.drools . StatefulSession class . StatefulSession extends WorkingMemory which has the above API . We look for the same function in org.drools.runtime.StatefulKnowledgeSession class . StatefulKnowledgeSession extends org.drools.runtime.rule . StatefulRuleSession which doesn t have method fireAllRules ( org.drools.runtime.rule . AgendaFilter agendaFilter , int fireLimit ) . We would like to have the API added so we can switch from the rule base to the knowledge base . 
Create live querries that receive change events , instead of using an iterable set . 
we should allow rules like when then and when eval ( true ) then 
rewriten integration test testDynamicRuleRemovals yields NullPointerException . Testcode after trace . ( + original Testcase not leaps compatible , does always create reteoo.RuleBaseImpl : public void testDynamicRuleRemovals ( ) throws Exception { Package pkg = builder.getPackage ( ) ; org.drools.reteoo.RuleBaseImpl ruleBase = new org.drools.reteoo.RuleBaseImpl ( ) ; ruleBase.addPackage ( pkg ) ; ) java.lang.NullPointerException at sun.reflect.NativeMethodAccessorImpl.invoke0 ( Native Method ) at sun.reflect.NativeMethodAccessorImpl.invoke ( NativeMethodAccessorImpl.java:39 ) at sun.reflect.DelegatingMethodAccessorImpl.invoke ( DelegatingMethodAccessorImpl.java:25 ) at junit.framework.TestCase.runTest ( TestCase.java:154 ) at junit.framework.TestCase.runBare ( TestCase.java:127 ) at junit.framework.TestResult $ 1.protect ( TestResult.java:106 ) at junit.framework.TestResult.runProtected ( TestResult.java:124 ) at junit.framework.TestResult.run ( TestResult.java:109 ) at junit.framework.TestCase.run ( TestCase.java:118 ) at junit.framework.TestSuite.runTest ( TestSuite.java:208 ) at junit.framework.TestSuite.run ( TestSuite.java:203 ) -- -- -- -- -- -- -- - Test code : modified org.drools.integrationtests.IntegrationCases.testDynamicRuleRemovals public void testDynamicRuleRemovalsUnusedWorkingMemory ( ) throws Exception { PackageBuilder builder = new PackageBuilder ( ) ; builder.addPackageFromDrl ( new InputStreamReader ( getClass ( ) .getResourceAsStream ( test_Dynamic1.drl ) ) ) ; builder.addPackageFromDrl ( new InputStreamReader ( getClass ( ) .getResourceAsStream ( test_Dynamic2.drl ) ) ) ; builder.addPackageFromDrl ( new InputStreamReader ( getClass ( ) .getResourceAsStream ( test_Dynamic3.drl ) ) ) ; builder.addPackageFromDrl ( new InputStreamReader ( getClass ( ) .getResourceAsStream ( test_Dynamic4.drl ) ) ) ; Package pkg = builder.getPackage ( ) ; org.drools.reteoo.RuleBaseImpl reteooRuleBase = null ; org.drools.leaps.RuleBaseImpl leapsRuleBase = null ; RuleBase ruleBase = getRuleBase ( ) ; //org.drools.reteoo.RuleBaseImpl ruleBase = new org.drools.reteoo.RuleBaseImpl ( ) ; if ( ruleBase instanceof org.drools.reteoo.RuleBaseImpl ) { reteooRuleBase = ( org.drools.reteoo.RuleBaseImpl ) ruleBase ; } else if ( ruleBase instanceof org.drools.leaps.RuleBaseImpl ) { leapsRuleBase = ( org.drools.leaps.RuleBaseImpl ) ruleBase ; } ruleBase.addPackage ( pkg ) ; WorkingMemory workingMemory = ruleBase.newWorkingMemory ( ) ; if ( reteooRuleBase ! = null ) { assertEquals ( 1 , reteooRuleBase.getPackages ( ) .length ) ; assertEquals ( 4 , reteooRuleBase.getPackages ( ) .getRules ( ) .length ) ; reteooRuleBase.removeRule ( org.drools.test , Who likes Stilton ) ; assertEquals ( 3 , reteooRuleBase.getPackages ( ) .getRules ( ) .length ) ; reteooRuleBase.removeRule ( org.drools.test , like cheese ) ; assertEquals ( 2 , reteooRuleBase.getPackages ( ) .getRules ( ) .length ) ; reteooRuleBase.removePackage ( org.drools.test ) ; assertEquals ( 0 , reteooRuleBase.getPackages ( ) .length ) ; } else if ( leapsRuleBase ! = null ) { assertEquals ( 1 , leapsRuleBase.getPackages ( ) .length ) ; assertEquals ( 4 , leapsRuleBase.getPackages ( ) .getRules ( ) .length ) ; leapsRuleBase.removeRule ( org.drools.test , Who likes Stilton ) ; assertEquals ( 3 , leapsRuleBase.getPackages ( ) .getRules ( ) .length ) ; leapsRuleBase.removeRule ( org.drools.test , like cheese ) ; assertEquals ( 2 , leapsRuleBase.getPackages ( ) .getRules ( ) .length ) ; leapsRuleBase.removePackage ( org.drools.test ) ; assertEquals ( 0 , leapsRuleBase.getPackages ( ) .length ) ; } } 
Camel integration for drools pipelines 
Up until now , the @ expires policy was handled by the engine as a hint on the expiration offset for events , but that was causing several mistakes and misunderstanding by users . So , change the @ expires policy to override and set a definitive expiration offset for events . Example : declare StockTick @ role ( event ) @ expires ( 10m ) end The above will cause StockTick events to be expired after 10m in memory , even if rules use temporal operators or sliding windows that would retain the event for more time , or would not require the event to be in memory for that amount of time . 
Allow users to clear specific agenda groups . 
Rules can be placed in an Xor Group . When a rule in an existing Xor Group fires it will cancel ALL other activations in that Xor Group . 
Improve the quality of the tests , add more test cases and clean the tests code . 
Decouple window definitions from pattern matching , allowing windows to be reused among various patterns/rules . 
This comes under the heading of I knew it would happen one day and I warned people about it but they didn t listen and Michael is always right in the long run , except when he predicted that the graphical web browser would NOT take off back in 1993 and was catastrophically wrong . Someone was having issues with concurrency ( 5 concurrent threads , but heavy load ) and creating a newWorkingMemory - there are hangs/lock issues with the weak hashmap that points from the Single rule base to the spawned working memories . This is not surprising , blah blah blah .... Anyway , one possible solution is to have a call where users who want to update an existing long lived working memory changes , pass in the WM to the rulebase , with say refresh rules - ie the methods like removeRule ( ) on a rule base , require a working memory to be passed in . We can still keep the old WeakHashMap , just make it non default behaviour ( it can not scale the way it is now - with the default behaviour in my opinion ) . STACK trace follows : I m using Java 1.5_09 on Linux . The app uses 5 simultaneous threads at the moment . They never share WorkingMemory instances but do share the same RuleBase . A thread dump ( see below ) shows all threads being stuck in java.util.WeakHashMap , which is called from AbstractRuleBase.addWorkingMemory . Has anyone seen this before ? I attempted to synchronize the method that s the entry point to newWorkingMemory ( ) . That definitely made the problem happen less often but didn t solve it completely . Anyone knows any other workarounds ? Thanks , Per CW4 prio=1 tid=0x1a4fd7a8 nid=0xc44 runnable & # 91 ; 0x1a2fe000 .. 0x1a2fefb0 & # 93 ; at java.util.WeakHashMap.expungeStaleEntries ( WeakHashMap.java:289 ) Source ) Source ) Source ) CW3 prio=1 tid=0x1a4fd5f0 nid=0xc43 runnable & # 91 ; 0x1a6fe000 .. 0x1a6fee30 & # 93 ; Source ) Source ) Source ) CW2 prio=1 tid=0x1a4fd100 nid=0xc42 runnable & # 91 ; 0x1a8e5000 .. 0x1a8e5eb0 & # 93 ; at java.util.WeakHashMap.expungeStaleEntries ( WeakHashMap.java:289 ) Source ) Source ) Source ) CW1 prio=1 tid=0x19afca78 nid=0xc41 runnable & # 91 ; 0x1a966000 .. 0x1a967130 & # 93 ; at java.util.WeakHashMap.expungeStaleEntries ( WeakHashMap.java:289 ) Source ) Source ) Source ) at CW0 prio=1 tid=0x19afc7d8 nid=0xc40 runnable & # 91 ; 0x1aafe000 .. 0x1aaff1b0 & # 93 ; at java.util.WeakHashMap.expungeStaleEntries ( WeakHashMap.java:289 ) Source ) Source ) Source ) at 
Currently you can not use relational operators for String fields . e.g . MyFact ( name & gt ; bbb ) org.drools.base.evaluators.ComparableEvaluatorsDefinition.evaluators has entries for ValueType.OBJECT_TYPE , but not for ValueType.STRING_TYPE . So it results in DescrBuildError : ========= Evaluator & gt ; does not support type ValueType = String : & # 91 ; Rule name= & # 39 ; Your First Rule & # 39 ; & # 93 ; Unable to create restriction & # 91 ; LiteralRestriction : & gt ; bbb & # 93 ; for field name in the rule Your First Rule : & # 91 ; Rule name= & # 39 ; Your First Rule & # 39 ; & # 93 ; ========= According to docs : 4.8.3.1.1.3.1 . Operators Other relational operatory may be used whenever the type values are ordered ; It is desirable to allow relational operators for String fields as String is Comparable . 
The main goal of this feature is to provide an unified mechanism to marshall objects that are used to persist the status of the knowledge session . Two different strategies were used by the sessionInfo and ProcessInstanceInfo marshallers with the Variable Persistence Strategies . 
Add the StrEvaluator to the list of core evaluators . Description can be found here : 
All types created or enhanced by a DRL declare construct must be retrievable from the KnowledgeBase using Declare getDeclare ( String pkg , String name ) A Declare object must provide getters String getPackageName ( ) , getName ( ) , Map & lt ; String , Object & gt ; getMetaData ( ) ( same as Rule ) A Declare object must provide Class & lt ; ? & gt ; getFactClass ( ) returning the created or enhanced java-lang.Class . A Declare object must provide long getInferredExpires ( ) returning ( for @ role ( event ) ) the inferred expiration offset or -1 if none . 
Refactor the default working memory out , so all entry points use the same code . 
Effective rule dates uses TimeMachine instead of the TimerService , so things are not unified 
Is it possible to support rulebase configuration via jsr94 registerRuleExecutionSet properties ? Suggestion : new property in org.drools.jsr94.rules.Constants.java:41 : //jh : added to support handing a rulebase config via jsr94 / * * & lt ; code & gt ; RuleExecutionSet & lt ; /code & gt ; rulebase config constant . * / public static final String RES_CONFIG = javax.rules.admin.RuleExecutionSet.config ; modification of method ( probably catch ClassCastException too , throw some jsr94 config exception ) org.drools.jsr94.rules.admin.RuleExecutionSetImpl.java:118 : RuleExecutionSetImpl ( ... ) : //jh : support rulebase configuration via jsr94 final org.drools.reteoo.ReteooRuleBase ruleBase = new org.drools.reteoo.ReteooRuleBase ( ( org.drools.RuleBaseConfiguration ) properties.get ( org.drools.jsr94.rules.Constants.RES_CONFIG ) , new Jsr94FactHandleFactory ( ) ) ; / * final org.drools.reteoo.ReteooRuleBase ruleBase = new org.drools.reteoo.ReteooRuleBase ( new Jsr94FactHandleFactory ( ) ) ; * / 
There are two main classloaders in Drools based around the Composite ClassLoader idea . This causes complexity and should be unified . 
A users should be able to specify dynamic execution for expressions that are not typesafe . this can now be done with the attribute @ typesafe ( false ) 
RuleTerminalNode and QueryTerminalNode are currently hard coded , please allow for a pluggable factory for these , so that end developers can easily experiment with different activation handlers . 
Java classes can be defined in DRL using the declare keyword . It would be good to be able to define Java 1.5 enums using declare too . We could then strip the proprietary Guvnor style enums from Guvnor and have the UI front DRL supported enums . Guvnor currently also supports related\dependent enums where the list of values for one enum is dependent upon the value from another enum : enum FUEL has values Petrol and Diesel , enum FUEL_DERIVATIVE has values Unleaded , Super unleaded , Bio-diesel and City disel . If FUEL.Petrol is selected then only FUEL_DERIVATIVE values of Unleaded and Super unleaded can be chosen . This functionality would still need to be provided by Guvnor as it is used as author-time restrictions not runtime . 
@ typesafe wasn t workign too well . So decided to simplify things . Now it ll only apply to the pattern that matches the object type from the type declaration . Also need to refactor things so that the MVELClassReader can take imports , for things like enums on Map keys - without having to fall back to Predicate . 
LeftTuples have more fields than the sink actually needs , which uses memory . In large volume systems the more memory we can save the better . The answer is each sink should specify the LeftTuple it needs . 
When declaring beans ( i.e . using the declare feature ) , if metadata attached to a class or a field corresponds to an actual @ Annotation , that @ Annotation should be present in the generated class . 
Migrate GEF rete viewer from branch 3.0.x 
I have made a small modification to WorkingMemory and AbstractWorkingMemory that allows me to pause and the restart rule firing . The change consists of adding a boolean isPaused flag ( plus gettter and setter methods ) which is then inspected in the while loop of the fireAllRules method as follows public synchronized void fireAllRules ( final AgendaFilter agendaFilter ) throws FactException { if ( ! this.firing ) { try { this.firing = true ; while ( ! this.isPaused ( ) & amp ; & amp ; this.agenda.fireNextItem ( agendaFilter ) ) { ; } } finally { this.firing = false ; } } } What is this good for ? It lets me stop rule firing from within some rule , e.g . when I want to execute an external call . The rule sets up the call and then calls setPaused ( true ) on WorkingMemory . Once fireAllRules exits , an external process executes the call , possibly asserting some facts into WorkingMemory and then calls setPaused ( false ) and calls fireAllRules again . Why not execute the call directly from the rule ? Because in my application the execution might take long time , and I want to have an option to move the WorkingMemory out of RAM , possibly moving it to another app server to continue firing after the externall call processing has completed . 
Here s what I d like to be able to do : rule serviceConflict when $ leftProcessAssignment : MrProcessAssignment ( $ service : service , $ machine : machine , $ leftId : id ) $ rightProcessAssignment : MrProcessAssignment ( service == $ service , machine == $ machine , id & gt ; $ leftId ) then scoreCalculator.addToHardScore ( 1 ) ; // No insertLogical or accumulate of those ConstraintOccurence s needed undo-then scoreCalculator.substractFromHardScore ( 1 ) ; end And here s a more complex example where the weight isn t a static 1 : rule serviceLocationSpread when $ service : MrService ( $ locationSpread : locationSpread ) $ spreadCount : Number ( intValue & lt ; $ locationSpread ) from accumulate ( $ location : MrLocation ( ) and exists MrProcessAssignment ( service == $ service , location == $ location ) , count ( $ location ) ) then scoreCalculator.addToHardScore ( $ locationSpread - $ spreadCount.intValue ( ) ) ; undo-then scoreCalculator.substractFromHardScore ( $ locationSpread - $ spreadCount.intValue ( ) ) ; // $ spreadCount should still be the same as it used to be end 
We should be able to use rules to declaratively control conflict resolution . 
We can link the VerifierComponent with their descriptions . This provides a simple access to information from the descriptions of the component or its associated VerifierMessageBase . I tested this by adding to the VerifierComponent constructor the BaseDescr : public abstract class VerifierComponent implements Comparable & lt ; VerifierComponent & gt ; , Cause { private BaseDescr descr ; public VerifierComponent ( BaseDescr descr ) { this.descr = descr ; } } And integrate that in all Visitors . This seems to work . ( ) What do you think of this , I can add test cases and provide a patch or git pull request . 
Generate invoker classes with ASM 
A trait is a ( partially ) implemented interface that can be attached ( and removed ) to an instance at runtime 
It would be good the possibility to add ( a optional ) name and description to each Resource in change-set . These attribute should be exposed by org.drools.io.Resource The attributes are not going to be exposed through knowledge-api yet . They are going to be implemented in org.drools.io.internal.InternalResource Even if these attributes don t have any effect in Resource s behavior and functionality , they will server as documentation of the change-set . 
JDT and other compilers work best when you throw a whole lot of source at them , not dribble it though . We can refactor PackageBuilder to build up a set of classes to compile and pass it to JCI at the last minute - the only trick is to map errors back from whence they came . This yields a 4X speed up in many cases . 
In RuleBuilder , it repeatedly hits the class type resolver to lookup classes over and over , even though a large ruleset typically only looks at a few classes . We can keep a cache at the PackageBuilder level and inject it into the RuleBuilder instances as they are needed . 
I have a method such as : / * determines if any of the events passed as parameter has occurred * / public boolean hasAnyEventOccurred ( String ... events ) { for ( String s : events ) { if ( hasEventOccurred ( s ) ) { return true ; } } return false ; } However in rules I can t call it like that : hasAnyEventOccurred ( event1 , event2 , event3 ) , I have to workaround as so : hasAnyEventOccurred ( new String { event1 , event2 , event3 } ) 
FROM MARK : =========== Edson , While I don t want to change to acc/for keyword quite yet , until we are sure what drastic changes we want to make to syntax . I think we can evolve accumulate ( ) 1 ) make the first , optionall & # 91 ; , ; & # 93 ; . Where the documented new separate is ; 2 ) functions are still , separated 3 ) allow an optional second ; after this boolean expression , an eval without the eval wrapper . 3. can be done now with a separate eval ( .... ) after the accumulate . But I think good to encapsulate the intent of the guard within the accumulate itself , it s also another opportunity to remove the eval keyword for a common use case . For now we ll just rewrite the accumulate to place an eval ( ) CE after the acc . It s a small win , which I think will make the DRL look nicer , especially for CEP use cases . ============ FROM EDSON : ============ Mark , ( 1 ) and ( 2 ) are ok . Regarding ( 3 ) , we can embed the expression in the accumulate node itself . No need for a separate node . And if we use ; as the separator , we don t need the eval ( ) keyword . 
It should be possible to use expressions , and bound variables in particular , with the timer attribute : rule Parametric timer timer ( expr : $ x , $ y ; ... ) when Bean ( $ x : delay , $ y : period ) then end 
Two distinct sets of rules might share the need for a common declared type , usually an internal utility fact The building process , however , forbids multiple declarations of the same fact in different DRLs . The quickest solution , removing the declaration from one of the two , might not be feasible when the two files have to be deployed independently as well as together . Externalizing the declarations to a third file might not always be feasible , especially when there is no full control on the DRLs ( e.g . generated automatically or acquired from external sources ) . The builder , then , should recognize equivalent declarations to an existing one and simply ignore them . 
Implement a backward compatible binary serialization framework for KnowledgeSessions , using Google s Protobuf framework . 
To allow to create rule chaining graphs and better detect circular issues , it is necessary to add some meta data to the Rule class describing which class of facts its consequence inserts , modifies or retracts . For both insertions and modifications it is also requested to determine the fields involved and whether they are populated with literals or variables . 
KIE-Server does not provide a command to advance the time of a pseudo-clock . This functionality is required ( or at least , highly useful ) when KIE-Server is used for CEP sessions . 
Trait - Core field mapping requires the fields to have the same name and compatible types . Whenever the names can not be the same , e.g . due to interface naming requirements , it could be desirable to define a custom mapping : declare trait X tfield : String @ Alias ( cField ) end declare Y cField : String end Here , tField should be mapped onto the hard field cField , even if the names are different 
It seems lots of people are forgetting to add dependencies . We should catch any thrown exceptions and then use refection to probe to see if the necessary classes from different required jars are present t , so we can give back a more meaningful message . 
At the moment in BetaNodes only equals constraint ( e.g . Person ( age == $ age ) ) are indexed . It is requested to create similar indexes also for comparison constraints ( e.g . Person ( age & gt ; = $ age ) ) 
Implement inline cast as described here : 
If the constraint invokes a constructor with a primitive type as argument but passing the corresponding class type to it as in the following example : class Person { public Integer getAgeAsInteger ( ) { return age ; } } rule R1 when Person ( new Integer ( ageAsInteger ) & lt ; 40 ) then end when the constraint is jitted the following Exception is thrown : java.lang.RuntimeException : Exception jitting : new Integer ( ageAsInteger ) & lt ; 40 at sun.reflect.NativeMethodAccessorImpl.invoke0 ( Native Method ) at sun.reflect.NativeMethodAccessorImpl.invoke ( NativeMethodAccessorImpl.java:39 ) at sun.reflect.DelegatingMethodAccessorImpl.invoke ( DelegatingMethodAccessorImpl.java:25 ) at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs ( JUnit4IdeaTestRunner.java:76 ) at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart ( JUnitStarter.java:195 ) at com.intellij.rt.execution.junit.JUnitStarter.main ( JUnitStarter.java:63 ) at sun.reflect.NativeMethodAccessorImpl.invoke0 ( Native Method ) at sun.reflect.NativeMethodAccessorImpl.invoke ( NativeMethodAccessorImpl.java:39 ) at com.intellij.rt.execution.application.AppMain.main ( AppMain.java:120 ) Caused by : java.lang.VerifyError : ( class : ConditionEvaluatord12c0fbaca644b0eaff422a71b8812cc , method : evaluate signature : ( Ljava/lang/Object ; Lorg/drools/common/InternalWorkingMemory ; Lorg/drools/reteoo/LeftTuple ; ) Z ) Expecting to find integer on stack 
Provide a null-safe dereferencing operator working as described in this post 
Add a mechanism for creating a Kjar , i.e . a jar containing all the information necessary to create already configured kbases and ksessions and refers to them using a unique name , both programmatically and with a maven plugin 
Externalizable always calls t he default constructor , so make sure all impl do nothing for the default constructor . will need to refactor code to also stop using them for convenience methods . 
Need to have BigDecimal support in the evaluators : Foo ( bigDecField & gt ; 2 ) so the literal is converted into a BigDec etc .. ( also BigInteger ) . Should not be too hard . 
This JIRA explains what improvements to the DRL parser could be very useful in the IDE . Currently , the eclipse IDE uses the rule parser to create an outline view based on the PackageDescr returned when parsing the DRL file retrieve all imports , all functions , all queries , all templates and the package of a DRL file ( so they can be used later , for example when performing auto-completion ) determine the location of the cursor when requesting auto-completion ( the part of the rule before the cursor is parsed , and based on the ( unsually partically incomplete ) PackageDescr returned by the parser , I try to determine in what kind of location the cursor is situation , e.g . the beginning of a column constraint , or inside an eval statement ) retrieve all parameters defined in a rule ( possibly before a certain location ) when auto-completion has been requested retrieve errors and warnings that signal certain syntax errors in the DRL file Other places were the results of the DRL parser could be used : determine which element is selected based on a character selection range provide real-time syntax checking determine what has changed after the DRL has been changed do refactoring automatic error solving Although the info returned by the parser is very useful , I think we are kind of reaching the boundary of what we can do with the info that is currently returned . I ll try to describe possible enhancements that could allow us to do more advanced IDE features as well . Use of character number in addition with line number + column Eclipse uses character numbers instead of line + column numbers in almost all situations . A character number describes at which location a certain character occurs since the beginning of the file ( and not like column since the beginning of the line ) . Although we could try to create a mapping between character number and line + column number , this has resulted in some annoying errors related to the newline character which is different on different platforms . Using character numbers would eliminate this problem . All elements in the PackageDescr should have a start location Currently , most do ( PatternDescr has a getLine ( ) and getColumn ( ) ) , but some elements in the PackageDescr returned by the parser still don t : FunctionDescr has no line and column imports are just strings the package has no location To be able to use this information for more advanced features , it would be necessary that all elements contain a start location ( now the IDE usually does additional parsing to determine the location of these elements ) . All elements should also have an end location Although PatternDescr has a getEndLine ( ) and getEndColumn ( ) , currently , only the end location of ColumnDescr is stored ( thx mic for adding this already since it was necessary for code completion ) . To be able to use this information for more advanced features , it would be necessary that all elements contain an end location ( now the IDE usually does additional parsing to determine the end location of these elements ) . For nested elements , this should be the same as much as possible Like RuleDescr contains ColumnDescr contains FieldConstraintDescrs , each of these elements should contain a start and end location ( where the start and end of the sub-descriptions are of course located inside the start and end location of its parent . I believe that this is already working quite well in the current implementation for the start location of elements . The parser should return as much info as possible , even if the rule is incomplete This is very important since the DrlParser is used a lot when the DRL is not yet completely finished ( for example when performing auto-completion ) . It would be crucial that the parser does not just return an error when it encounters an error , but tries to parse the remainder of the file as well , and tries to return as much info as possible . For example , when trying to parse the following incomplete rule : rule MyRule MyClass ( the parser should ideally return a RuleDescr with name MyRule , containing as lhs one ColumnDescr , with name MyClass , a start location , but no end location ( since the end of the ColumnDescr has not been reached yet , since the closing bracket is missing ) . This used to work like this in the 3.0.x release . I have noticed though that the 3.1 branch now returns null as only sub-description . Similarly , when using an eval , currently the EvalDescr is only added to the RuleDescr once the eval has been closed . As a result , the IDE has to redo a lot of parsing to check for these situations as well . If the parser always returns as much info as available ( by for example adding subdescr once they are started , not only when they are finished ) , the IDE would not have to do as much parsing itself . All errors and warnings try to give exact locations in the drl Although previous improvements have made the errors returned by the parser already very useful , more precise feedback could be given when the exact location of the errors could be returned , preferably as character start and end , but line numbers can be used here as well . Currently , the error is mostly indicated on the start line of the rule that contains the error . More precise error determination is necessary for more precise error visualization , automatic error solving , etc . I hope this kind of explains what improvements to the parser could be very useful to the IDE and why . 
The idea is to use dynamic proxies to support shadow facts . So changes to the facts can be queued up , and the shadows refreshed when propagation has finished . 
Forward Chaining means that facts are asserted and propgated forward throughout the network , during forward propagation matching takes place which results in rules being fired - the rules are event based , in that they are fired in response to changed in the working memory . Backward chaining is query based . Rules attempt to fire first but do not have the necessary matched facts , so facts are pulled in from an external source . 
The profiling shows that much time is spent in iteration loops . So we should look at using Single and Composite Adapters for propagations . Further we should avoid using ArrayLists and instead use our own custom LinkedList or arrays . 
Rule Engine should allow the WM to be querried . 
Instead of cloning FactHandle & # 91 ; & # 39 ; & # 93 ; arrays , which is expensive , as its creating factorial too many objects , we shoudl instead looked to some sort of linked list ; so that it doesn t need to copy the information of the parents . 
Would be nice to have some construct like Person ( address == null or age & lt ; 30 ) which would kind of short circuit ( ideally ) . Could be done as a special thing with alpha nodes , or another type of join node , or something else . This is a common problem to have for users . 
Implement alpha node hashing in ObjectTypeNodes to improve performance . 
We would like to be able to specify a default expiration offset for events . The default expiration offset should be used if the inferred expiration offset is infinite . Benefits would be : Expiration is guaranteed : either after the specified offset or after the inferred offset . Rule authors are not required to include a temporal constraint in all rules . Event classes can be designed if the rules are not yet known . The current behavior of @ Expires ( fixed expiration offset ) could be the default and an optional attribute could be added to enable the new behavior . @ Role ( Type.EVENT ) @ Expires ( value = 10m ) // fixed expiration offset or @ Expires ( value = 10m , type= fixed ) // fixed expiration offset public class MyEvent { New behavior : @ Role ( Type.EVENT ) @ Expires ( value = 10m , type= default ) // new feature public class MyEvent { The goal is to have automatic event lifetime/memory management at all times . At the moment either a fixed expiration offset has to be set , which is only possible after analysing all rules and determining the expiration offset manually . Or every rule must include some temporal constraint , which is sometimes a tough burden on the rule author . This feature is related to : I think the new behavior would touch the same code as the fix implemented there by 
Queries should be able to specify how the results are processed once they reach the terminal node . 
This is essentially a port from 2.x codebase . It will have a new front end class that makes the semantics of invoking it clearer . Initially it will output DRL , after this point it can call the parser directly for LHS , RHS etc ... 
I need to count the number of sub-objects that meet various criteria . As an example , suppose I have several hundred Town objects , each of which has a list of perhaps a few hundred Person objects . I need to write rules like : Find all the towns that have more than three disabled people with incomes over $ 100K . For each town with more than 1000 residents that has more than 50 poor children under the age of 8 , add a teacher for every 25 children . I m shaky on JBR syntax , but I think those would translate to something like : rule disabled when ArrayList ( size & gt ; 50 ) from collect ( Person ( disabled == yes , income & gt ; 100000 ) from town.getPersons ( ) ) then //do stuff end rule teachers when town : Town ( population & gt ; 1000 ) count : Arraylist from collect ( Person ( disabled == yes , income & gt ; 100000 ) from town.getPersons ( ) ) count ( size & gt ; 50 ) then town.addTeachers ( count.size ( ) / 25 ) end ( I m not really working with towns and people , but it makes for easily understood examples ) 
Currently , exists conditional element is implemented as a sequence of 2 not nodes . This is suboptimal for performance and adds complexity to the network with specialized constraints and the requirement for a specific RightInputAdapterNode . Also , the currently implementation causes unnecessary work to be performed . For instance , trace the work done in the terminal node in the following example : package org.drools query 2 persons with the same status p : Person ( $ status : status , $ age : age ) exists Person ( status == $ status , age & gt ; $ age ) ; end So , replace current implementation for a specialized ExistsNode . 
Implement support to additional predicate syntax , making - & gt ; not mandatory anymore . Pattern ( $ var1 : attr1 , $ var2 : attr2 , ( $ var1.blabla ( ) ! = $ var2.xyz ( ) ) ) 
I d like to be able to write a constraint to determine if a field s value is a member of some collection . This is the inverse of the contains keyword . The proposed syntax is : & # 91 ; bindingVar : & # 93 ; & lt ; fieldName & gt ; in & lt ; someCollection & gt ; ( I m not picky about the keyword , other possibilities are containedBy or memberOf , but in is a single word ) Use case : I have a container class with a field that exposes a collection of record numbers . In the working memory , I have a bunch of record objects , and one container object . I want to write a rule that fires when it encounters a container that has records matching some criteria : when Container ( $ recordNums : records ) Record ( number in $ recordNums , otherField == somevalue ) then doStuff ( ) ; The current workaround is : Record ( num : number - & gt ; ( $ recordNums.contains ( num ) ) ) Which is problematic , as the predicate may not be time-constant . 
We are moving from JFDI to MVEL as its actively maintained and championed 
effective-date expires-date attributes . 
We need to support XML bindings for the Descr classes . ( starting with PackageDescr specifically ) . XMLBeans or similar etc . The idea is to provide some XML support for those who need to use XML authoring , or generating tools , and also provide a native Drools XML format for use with XSLT for RuleML , OWL etc .... Should be 1 to 1 with the Descr AST classes mostly . 
Inline JCI and strip all uneeded dependencies , like collections , lang , io and logger . 
Make the TMS optional , but by default on . This should help reduce memory usage on lage systems . 
Inline Objenesis ( ) library and start using it to remove the requirement of noarg constructor for fact classes ( as previously , ShadowProxies required that ) . 
Implement a programmatic RuleEventListener with the lifecycle described in 
Eclipse JDT and Janino now support static imports , while still targteting jdk1.4 byetcode . 
pushed and popped agneda groups should be exposed in the event model .. 
lock-on-attribute stops the active ruleflow/agendagroup for the currently evaluating rule from reveiving any activations 
RuleBase now returns two sessions , StatelessSession and StatefulSession . 
It should not be possible to add invalid rules to a package . 
JSR94 Implementation and Tests shifted from Drools2.5 to Drools 3 Please integrate JSR94 to Drools 3 . Look at the zip , which already contains everything . All uncommented Tests ( TCK/JSR94 ) are running . 
Move the templating to MVEL , so we can drop antlr2.7.7 and StringTemplate3.0 
p : Person ( p.name == bob ) Some users may write rules this way and it can help with code generation , so that you can use the same statements in the field constraints as you can in the eval ( when using something like MVEL ) . 
Allow an expression to express a salience value dynamically . 
A debug view which shows a realtime audit log of the selected working memory ( logger ) . 
The builder in the IDE should also look for .package files in the same directory and take them into account 
Currently properties are only assignment by the system properties method , we need a cascading system with auto discovery . 
We need to make sure that our LogicTransformer is implementation correct . 
At the moment if you configure drools to work with the old ReteOO engine but you don t have the drools-reteoo.jar on the classpath you get a ClassNotFoundException . In this case it is requested to log a warning and automatically switch to phreak . 
querries should allow parameters to be passed . 
Move shadow facts to core . This involves creating a new classloader to hold these generated classes , as we no longer know the PackageStoreData to use . 
ConflictResolution should be configurable and set by the RuleBaseConfiguration . 
assert becomes insert modify becomes update asertObject , modifyObject becomes insert and update 
Advanced users should be able to disable shadow facts , using a properties setting for RuleBaseConfiguration . 
Implement incremental accumulation/collection for accumulate and collect CE 
When an Object is asserted if there are no ObjectTypeNode matches , then we need to auto create an ObjectTypeNode so its remembered . This ensures any future added rules will have those facts propagated . 
All , Today I used a few hours to develop something I think it is quite useful : the ability to have externally coded functions for accumulate . Basically , the idea is that common functions should have a predefined template and not be coded in every accumulate of every rule in your rule base . Example : average The idea is that instead of writing something like bellow in every rule : $ avg : Number ( ) from accumulate ( Cheese ( $ price : price ) , init ( double total = 0 ; int count = 0 ) , action ( total = $ price ; count + ; ) , reverse ( total = $ price ; count - ; ) , result ( new Double ( total / count ) ) ) The user could simply use a predefined function like : $ avg : Number ( ) from accumulate ( Cheese ( $ price : price ) , average ( $ price ) ) ; Or if he wants to know how much will cost him to give 10 % raise to all employees of a given department : $ sum : Number ( ) from accumulate ( Employee ( dept == X , $ salary : salary ) sum ( $ salary * 0.1 ) ) And whatever the user wants to do . So , instead of hardcoding a few functions , I thought it was better to let it pluggable . So I defined a simple interface ( AccumulateFunction ) and anyone willing to create an external function simply implement this interface and wires it using either the PackageBuilderConfiguration API or the configuration files mark created . Example : drools.accumulate.function.average = org.drools.base.accumulators.AverageAccumulator Where drools.accumulate.function . is a constant prefix and average is the function identifier the user will use in the rule file ( DRL , XML , etc ) . Also , we will provide common functions like average , sum , count , min , max , etc , out of the box , since it is really easy to implement any function . Example : to implement the average function , all one needs to do is : package org.drools.base.accumulators ; / * * An implementation of an accumulator capable of calculating average values * @ author etirelli * * / public class AverageAccumulator implements AccumulateFunction { protected static class AverageData { public int count = 0 ; public double total = 0 ; } / * ( non-Javadoc ) @ see org.drools.base.accumulators.AccumulateFunction # createContext ( ) * / public Object createContext ( ) { return new AverageData ( ) ; } / * ( non-Javadoc ) @ see org.drools.base.accumulators.AccumulateFunction # init ( java.lang.Object ) * / public void init ( Object context ) throws Exception { AverageData data = ( AverageData ) context ; data.count = 0 ; data.total = 0 ; } / * ( non-Javadoc ) @ see org.drools.base.accumulators.AccumulateFunction # accumulate ( java.lang.Object , java.lang.Object ) * / public void accumulate ( Object context , Object value ) { AverageData data = ( AverageData ) context ; data.count++ ; data.total += ( ( Number ) value ) .doubleValue ( ) ; } / * ( non-Javadoc ) @ see org.drools.base.accumulators.AccumulateFunction # reverse ( java.lang.Object , java.lang.Object ) * / public void reverse ( Object context , Object value ) throws Exception { AverageData data = ( AverageData ) context ; data.count -- ; data.total -= ( ( Number ) value ) .doubleValue ( ) ; } / * ( non-Javadoc ) @ see org.drools.base.accumulators.AccumulateFunction # getResult ( java.lang.Object ) * / public Object getResult ( Object context ) throws Exception { AverageData data = ( AverageData ) context ; return new Double ( data.count == 0 ? 0 : data.total / data.count ) ; } / * ( non-Javadoc ) @ see org.drools.base.accumulators.AccumulateFunction # supportsReverse ( ) * / public boolean supportsReverse ( ) { return true ; } } 
when a new Rule is added that adds new ObjectTypeNodes we need to scan all other ObjectTypdeNodes to see if their contenst are assignablefrom . This ensures that we propagate facts from List and ArrayList . One key part to this is to make sure we remove redundance , we don t want to propagate a fact twice because it matches both List and ArrayList . 
Stateless Sessions are not currently re-usable . To make them useable you will have to allow those sessions to inject the globals and event support objects . 
We need integration tests for Duration , make sure they work with no-loop too . 
Consider the following scenario : declare trait A sub : int end declare X end declare trait Foo fld : A end declare Bar @ Traitable ( logic = true ) // new mode fld : X end If an instance b of Bar is traited with Foo , the value of its field fld should in turn be traited with A . Truth maintenance and transparent casting are required . The goal is to write rules such as : when Foo ( fld isA A , fld.sub == 0 , .... ) then .. 
add integration tests for no-loop . 
add integration tests for agenda groups 
We added setGlobalResolver , getGlobalResolver is also needed . Also the working memory should no longer handle any form of chaining , should just check the provided , or default , resolver . 
Rules are not obeying no-loop , where the root node , after the lian , are eval , not and exists . This is because the parent chain skips nodes . We need to not skip nodes in the reference chain , and instead skip during iteration . 
Ruleflow and agenda groups have been unified since 6.x Specifying both attributes in a rule will result in one of them being overwritten . Specifically , RFGs are implemented using AGs , but the RFG name is the one that will be used in case of a conflict . A warning should be generated in case of potential conflicts 
Implement a new @ Datadriven annotation . A rule annotated with it will behave eagerly as in rete . 
The incremental update feature of Drools allows me to incrementally update not only the KieBase , but also the KieSession . I have a use-case where my updated rules have different globals defined ( different classes ) than the original rules , with different names . When I set a global on a KieSession , Drools explicitly checks whether that global is defined in the KieBase , and if not , it will throw an error . However , when I incrementally update the KieBase , and a global is removed from the rulebase , that global is not removed from the MapGlobalResolver map , potentially causing issues ( e.g . memory leaks ) . When a session is incrementally updated , and globals are no longer defined in the new rule-base , they should be removed from the MapGlobalResolver . See reproducer here : Clone the repo and run mvn clean test . 
Prior to Java 8 it was possible to disable constraints jitting by setting the drools.permgenThreshold to 0 . Since with Java 8 they removed the PermGen space , is no longer possible to control and disable constraints jitting . It is required to provide a new option , named drools.jittingThreshold , through which it will be possible to configure after how many interpreted evaluations a constraint should be jitted . Special values for this property will be : 0 - & gt ; force immediate synchronous jitting ( it s adviced to use this only for testing purposes ) . -1 ( or any other negative number ) - & gt ; disable jitting Default value is 20 . 
when a rule uses a java class in a pattern : package my.test ; import org.drools.Cheese ; rule R when Cheese ( ) then end a TypeDeclaration for that class ( e.g.Cheese ) is created , but is assigned to the rule package ( my.test ) rather than to the natural class package ( org.drools ) . This prevents an efficient later lookup of the typeDeclaration using the class name as a key . 
It should be possible to bind and then reason over facts not in the working memory for the current rule . Its important to remember that the derived facts should be time constant . 
I ve got a use-case where I , at runtime , want to inspect the rule-attributes of our rules ( e.g . salience , ruleflow-group , etc . ) via the Drools API . Currently , the only way to retrieve that kind of information is via the internal Drools API , ie . org.drools.core.definitions.rule.impl.RuleImpl . It would be nice if we could expose these rule attributes via a public API . 
Take a given AND Conditional Element and turn it and all its children into a Rete network . 
We need the AuditFileLogger to work with both stateful and stateless sessions , so the event management methods need to be refactored to a common interface . 
current the configuration for dialects are hard coded into the main PackageBuilderConfiguration , we need to refactor the configurations to also be pluggeable . 
We should allow clips style templates for Columns 
we need integration tests for retract , assert , modify - also make sure that drools.assertObject , drools.retractObject , drools.modifyObject all work . 
RuleBaseConfiguration should allow the user to specify a custom handler for consequence exceptions . 
Most likely an oversight . However , to keep the stateless nature of the API - there isn t another way to do this other then add more methods to the interface , unfortunately . 
We know the method name for each descr . If we move the params all onto a single line we can use indexof to fine the start of each descr compiled code . We can then use that to find the offiset and map the error to the descr . This is complex as the error handling needs to be reworked . CompilationProblem objects should NOT be stuffed inside rule errors , but be seperate rule errors ( hence can have multiple line errors ) . 
Users want to be able to add || and & amp ; & amp ; inside a column . || outside of a column results in multiple sub rules . However || inside a column should result in nesting the values inside a single alpha node , this should be the same for & amp ; & amp ; . However using a , will still result in a alpha node per entry . 
On the LHS for normal constraints , we coerce String - & gt ; Date ( via DateFactory ) . Make MVEL do the same for actions ( so you can have a date literal as a string rather then all the guff you have to go through to setup a date ) . 
Actions in ruleflow now only support MVEL . It should also support other dialects like Java . 
add lock ( ) and unlock ( ) to RuleBase and setup a rulebase listener to progated the fireAllRules calls . 
Allow predicates to be nested inside a field constraint 
& # 91 ; Edson said there might be already such an issue , but I couldn & # 39 ; t find it looking through jira. & # 93 ; Something like this should be possible : $ multipleQueensHorizontal : Long ( ) from accumulate ( $ q1 : Queen ( $ id : id , $ y : y ) ; Queen ( id & gt ; $ id , y == $ y ) ; , count ( $ q1 ) ) ; 
This is needed for testing effective dating . 
If I set my rule base to use equality-based assert behavior , I m expecting to be able to use the getFactHandle ( object ) method to retrieve a previously asserted fact by providing an equivalent ( by equals ( ) and hashCode ( ) ) object as an argument . This appears to not be the case , as AbstractWorkingMemory uses it s identityMap and associated IdentityAssertMapComparator to do the getFactHandle lookup instead of the assertMap and EqualityAssertMapComparator . This causes the lookup to be done with the system hashCode ( ) method and not the overridden version supplied in my fact class . The lookup thus fails and returns null . See attached unit test . 
add logical assertion tests 
We don t always want to use Rules for our constraints , so also allow dialectable eval type decisions . 
The parser should detect Class.FIELD and when assigning it to LiteralDescr set a field called staticFieldValue to true . 
add not contains and not matches constraints Person ( addresses not_contains foo ) simple extension to the contains feature for collections . Any other sytax ideas ? Person ( something ! contains foo ) Person ( something ! & lt ; & lt ; foo ) Person ( something & lt ; & lt ; foo ) I prefer as natural as possible ... 
We need an async assert . This means the fact is is asserted and immediately returns . Internally there is a consumer/provider based queue that one by one asserts the stacked items into the working memory . Need ot make sure that users can handle async exceptions . There might also be some settings to do with 2 phase commit , in that when do we call fireAllRules ? Do we call it after every assertion , after a set time period , after X facts are asserted - or maybe a combination of both ? Initially probably esiest to just call fireAllRules on each assertion from the Queue . I recommend that thechannel code stuff be borrowed from - only take hte classes you need and refactor them for org.drools.util.concurrent . 
Currently drools-core has the RuleBase directly coupled to PackageCompilationData , we need to de-couple that around the dialect framework . 
Enhanced XML-based process definition language . 
Context introduced as a new concept to easily group nodes in a certain context . Used as the basis for : Variable scope Exception handling Swimlanes 
Support for timers in workflow languages 
We need a pluggable scheduler api that the drools components can code against , while being protected against the underlying implementation . We also need a default JDK ScheduledThreadPoolExecutor as well as Quartz impl . 
Remove all the ShadowProxy impementation except minimal support for the interface alone , leaving it to the user to implement them if they need it . 
