pluggabl execut engin p effort adapt work use apach tez http nofollow http make chang allow clean executionengin abstract exist chang major alreadi rel abstract frontend backend chang attach commit essenti barebon chang 8211 tri chang structur differ compon much think interest see futur refactor area realli honor abstract frontend backend p chang reinstat executionengin interfac tie togeth front end backend make chang deleg ee necessari creat mrexecutionengin implement interfac work includ chang exectyp cycl executionengin classpath select appropri one do use java serviceload exactli mapreduc choos framework use local distribut mode also tri make scriptstat jobstat pigstat abstract possibl current state think futur work need do perhap usag scriptstat respons differ statist class touch ppnl think abstract need perhap separ patch 
add deepcopi logicalexpress p would use way deepcopi express deepcopi creat new object chang make one object reflect copi 2 reason overrid ul li may well use deepcopi sinc copi semant explicit sinc deepcopi may expens li second import reason defin deepcopi separ routin pass plan argument updat express copi p usag would look like follow div preformat panel 1px div preformattedcont panelcont pre logicalexpressionplan logicalplan new logicalexpressionplan logicalexpress copyexpress logicalplan p immedi motiv would construct express constitut cnf form 
merg join support replic join predecessor p sinc replic join trigger reduc chang output order merg join work 
support udf foreach merg join p right mapsidemergevalid outright reject foreach udf div code panel 1px div codecont panelcont pre span privat span boolean isacceptableforeachop oper lo span throw logicaltophysicaltranslatorexcept span lo span instanceof loforeach operatorplan innerplan loforeach lo validatemapsidemerg innerplan span return containsudf loforeach lo span els span return span fals p todo later class insid containsudf div code panel 1px div codecont panelcont pre span todo dvryaboy span futur could relax span rule trace field span pass udf refus span udf work span join key transform field p todo relax requir remov altogeth 
allow avrostorag use class schema p manag avro schema sourc code java class avro would easi someth like blockquot p store use avrostorag null p rather pass first agur entir avro schema json script keep potenti outdat set avro schema file hdf p classpath alreadi awar avro datum would good leverag fulli qualifi 
build udf give string search replac occurr search key replac valu p let say string a1b2c3d4 object replac 1 b 2 c 3 4 deriv 11223344 string p use exist replac method p replac replac replac replac a1b2c3d4 1 b 2 c 3 4 p propos udf method p gener syntax p sourcestr search1 replacement1 p a1b2c3d4 1 b 2 c 3 4 p advantag p 1 function call reduc 2 eas code good p let know input udf piggi bank take base 
authent kerbero use keytab file p run kerbero secur environ user face limit job run long remain ticket lifetim kerbero ticket environ work ticket expir 10 hour thu limit maximum job durat 10 hour problem p hadoop tool featur authent use kerbero keytab file essenti file contain encrypt form kerbero princip password use run applic request new ticket kerbero server initi ticket p applic commonli includ two line div code panel 1px div codecont panelcont pre span system span span span nbasj span p way run apach flink base applic 170 hour week kerbero secur yarn p propos featur set relev kerbero valu script abl run job mani day secur p propos look script div code panel 1px div codecont panelcont pre set set nbasj set p iff set least last two aforement method call submit job 
need nativ keyword p assum user job break easili three piec assum piec one three easili express piec two need write map reduc whatev reason perform someth could easili express legaci job import chang today user would either use map reduc entir job manual handl stitch togeth map reduc job instead provid nativ keyword would allow script pass datum stream underli system case map reduc semant nativ would vari underli system map reduc case would assum indic collect one fulli contain map reduc job would store datum invok map reduc job read result datum continu might look someth like div code panel 1px div codecont panelcont pre load myfil x load myotherfil b group 0 c foreach b gener group myudf b span nativ e join 0 x 0 p differ stream allow user insert arbitrari amount nativ process wherea stream allow insert one binari also differ stream datum pipe directli binari part pipelin pipelin would break datum write disk nativ block invok datum read back p anoth altern say unnecessari user coordin java use pigserv interfac run call map reduc job explicitli advantag nativ keyword user need worri coordin job take care also user make use exist java applic without java 
support flatten map p come across user ask quit time see support flatten instead user write udf 
statist record read mapper reduc p use counter framework hadoop initi interest find number record read particularli last job script sampl code access statist last job p string reduceplan reduceplan null record write p els record write p patch contain 7 test case includ test pigstorag binstorag along one multipl mr job 
autocomplet complet alia p autocomplet know keyword differ context would nice complet alia alia 
logic optim push project p continu work http nofollow need add anoth rule logic optim push project ie prune column earli 
add limit statement work nest foreach p like comput top 10 result p natur way express would div code panel 1px div codecont panelcont pre load use pigstorag date span int count span int url chararray b group date c foreach b order count desc e limit 10 gener flatten e dump c p yeah could write udf piggybank function take top n result sinc limit alreadi exist statement seem like also work nest foreach p exampl workaround div code panel 1px div codecont panelcont pre c foreach b order count desc e 10 gener flatten e dump c 
serial schema pigstorag storag type p find pigstorag realli conveni storag datum interchang compress well import excel analysi environ p howev pain come mainten column fix locat like add column p would great load pigstorag could read default schema file store datum store pigstorag could store file p test hadoop hdf local mode ignor file call directori part p exampl chain script execut p load use pigstorag int b int p store use pigstorag p b load use pigstorag p describ b p describ b output someth like int b int 
support cast chararray simpl type p support cast chararray integ long float doubl bytearray convers fail reason overflow cast return null log 
default parallel p hadoop 20 user specifi number reduc hadoop use 1 reduc default valu differ previou hadoop default reduc number usual good 1 reduc user want sure although user use parallel keyword specifi number reduc statement wordi need conveni way user express desir number reduc propos p 1 add one properti user set script eg set 10 p 2 hint free optim number reduc unlik parallel keyword current sinc mechan determin optim number reduc alway grant unless overrid parallel p 3 user put multipl insid script last entri 
udf script languag p possibl write udf script languag python rubi etc free user need compil java gener jar etc also open programm prefer script languag 
acummul interfac udf p add accumul interfac udf would allow take set number record time instead entir 
perform implement group oper speed process order datum p gener group oper need mapper reduc aggreg do reduc incur disk mapper p howev case input datum follow properti p 1 record key group togeth datum sort key 2 record key mapper p group oper perform mapper thu remov overhead disk p alan propos add hint group claus like one div code panel 1px div codecont panelcont pre load input use someload b group 0 use span mapsid c foreach b gener p propos addit use mapsid group mapsid group oper collect record give key buffer see key chang emit key bag record buffer assum key give record collect togeth thu need buffer across key p expect someload implement datum system zebra ensur datum emit loader satisfi properti 1 2 p respons user loader guarante properti 1 amp 2 invok mapsid hint group claus runtim check error input p group claus mapsid hint latin support group column includ group express group 
provid much easi use accumul interfac accumul abl p introduc new interfac iteratingaccumulatorevalfunc name final cool thing patch build pure top exist accumul code well use http accumul abl del could easili work without say easi way write accumul without fork p downsid way abl provid clean interfac use second thread need explor potenti perform implic give easi use stuff perform implic think long measur document worth much usabl interfac plu think bad one thread heavi lift anoth ferri valu sum could write div code panel 1px div codecont panelcont pre span public class sum span extend iteratingaccumulatorevalfunc lt span long gt span public span long exec iter lt tupl gt span throw ioexcept span long sum 0 span sum span long 0 span return sum p besid perform test need figur properli test sort thing particularli welcom advic p accumul current forc process whole bag getvalu call p earli termin handi featur abl use isempti exampl p add new interfac extend 
zebra sort tabl support zebra p new featur zebra support sort datum storag storag librari zebra sort datum support creation use sort datum either pig task use zebra storag p sort tabl keep datum total sort manner across tfile creat potenti mapper p sort datum creation pig store oper input datum sort order new zebra tabl mark sort sort column p sort datum creation though task three new static method basictableoutput class provid allow help user achiev goal setsortinfo allow user specifi sort column input tupl store getsortkeygener getsortkey help user gener key accept zebra sort key base upon schema sort column input p sort datum read pig load oper pass string sort extra argument tableload constructor ask sort tabl load p sort datum read task new static method tableinputformat class requiresortedt call ask sort tabl read addit overload version new method call ask sort tabl specifi sort column p releas sort tabl support sort ascend order descend order addit sort key must simpl type complex type record collect map p sort support order multipl sort key signific first sort column primari sort key second secondari sort key p releas sort key store along sort column key origin creat result datum storag 
nest cross p use cross insid foreach nest statement one typic use case nest foreach cogroup two relat want flatten record key process natur achiev cross eg div code panel 1px div codecont panelcont pre c cogroup user uid session uid foreach c cross cross user session flatten two input bag filter filter cross user session result foreach cross gener processsess user user session nest foreach jira gener result p cross user write udf process bag user session much hard udf process flatten tupl especi true nest foreach statement http support 2 level nest foreach del p candid project googl summer code 2011 inform program find http nofollow http 
custom partition p add custom partition give control output partit key go add keyword languag p partit udf p similar syntax udf return number 0 n number output 
make work hadoop p need make work hadoop svn branch current http nofollow http 
abl set job prioriti latin p current user set job name latin say p set job name p abil set prioriti would also nice patch small goal abl say p set high p throw jobcreationexcept jobcontrolcompil prioriti one allow string valu enum low normal high case insensit make littl 
support skew outer join p similarli skew inner join skew outer join help scale presens join key fit memori 
zebra order preserv sort tabl union p output schema adopt schema union semant name output column appear one compon tabl result row valu column row compon tabl null otherwis hand output column appear multipl compon tabl type column compon tabl must ident otherwis except throw result row valu column row compon tabl column null otherwis p order preserv result could index compon tabl project contain column name specifi compon tabl index output posit specifi project list underli tabl union sort tabl use special column name project caus except throw p attempt make creat tabl column name excpet throw name reserv zebra virtual name 
zebra support record row file split zebra tableinputformat p tfile current support split record sequenc number see jira http split tfile record sequenc number del want util provid record row input split support one promin benefit case larg datum file creat much input split creat one big split one big p detail new getsplit work default user specifi split gener follow 1 select big column group term datum size split tfile accord hdf block size 64 mb 128 mb get list physic byte offset output per tfile exampl let we assum 1st tfile get offset1 offset2 offset10 2 invok long offset get recordnum pair near byte offset exampl say get recordnum1 recordnum2 recordnum10 3 stitch span error 91 0 recordnum1 93 span error 91 recordnum2 93 span error 91 recordnum10 93 span error 91 lastrecordnum 93 split column group respect form 11 input split 1st tfile 4 input split need creat tfile scanner long beginrecnum long endrecnum p note convers byte offset record number do mapper rather done job initi phase due perform concern sinc convers incur tfile read 
rank function like sql p implement function give sort bag add tupl uniqu increas identifi without gap like rank p candid project googl summer code 2012 inform program find http nofollow http p function implement far avail http nofollow http 
pass jobconf udf specif configur inform udf p user long ask way get jobconf structur udf would also nice way pass properti front end back end udf store state pars time use p patch part propos http pass global configur udf del provid way give user specifi configur file udf mark 602 depend bug 
udf dynam invoc simpl java method p need creat wrapper udf simpl java function creat unnecessari work user slow develop process produc lot trivial class use java reflect allow invok number method fli dynam creat gener udf accomplish 
zebra zebra column group access control p access control process tri read column group zebra abl handl allow disallow access secur eventuallt grant correspond hdf secur datum p expect behavior column group permiss set p user select column permiss access zebra return error messag error permiss deni access column lt column name name gt p access control appli entir column group column column group permiss 
pigunit script test simplifi p goal provid simpl xunit framework enabl script easili ul altern squar li unit test li regress test li quickli prototyp p cluster set p exampl p testcas div code panel 1px div codecont panelcont pre test span public void testtop3queri span string arg span test span new pigtest span arg span string input span span span span span span string output span span span span datum input span output p div code panel 1px div codecont panelcont pre datum load input queri chararray count int foreach gener group queri sum count limit n store output p 3 mode ul li local properti present li mapreduc use cluster specifi classpath ul li automat mini cluster default class path li point exist cluster properti present p would nice see idea could integr piggybank could improv interfac order make pigunit p compon base pigunit could build later ul altern squar li standalon miniclust li notion workspac test li standalon util read test configur gener test report p first prototyp open suggest definit take advantag p test div code panel 1px div codecont panelcont pre appli patch ant ant ant test p take 15 min mapreduc miniclust test need split futur unit integr p mani exampl div code panel 1px div codecont panelcont pre p use standalon forget cluster 
monitor kill runaway udf p safeti measur sometim use monitor udf execut often prefer return null default valu instead time runaway evalu kill job past see complex regular express lead job failur due half dozen million particularli obnoxi p would great give user lightweight way enabl udf 
add boolean data type p need boolean datum type depend p volunt anyth beyond work plu unit test make work p candid project googl summer code 2011 inform program find http nofollow http 
support union oper merg base column name p datum schema often make sens union column name schema rather posit column behavior exist union oper remain backward compat p featur support use either new oper extend union support use claus think new oper call either unionschema merg anybodi suggest syntax p exampl p l1 load x b l2 load b c u unionschema l1 l2 p describ u u bytearray b byetarray c bytearray 
emb script languag p possibl emb call script languag let function defin script avail spin http nofollow http let user defin udf script 
support 2 level nest foreach p would like gener certain metric everi list impress context page like click page etc first group get click impress togeth would want iter one per comput metric sinc nest foreach within foreach support end write udf take bag comput metric would eleg keep logic iter record outsid pig script p pseudocod would like write div code panel 1px div codecont panelcont pre let we say page context click rank 2 span 3 ad a1 load rank click a2 load rank impress b cogroup a1 a2 let we say b contain follow schema group a1 a2 record would b would 2 1 2 3 c foreach b gener flatten a1 flatten a2 wont work current well basic would like repres entir serv foreach gener a2 rank someudf a1 rank a2 udf return valu like v1 v2 v3 depend a1 a2 output 1 v1 2 v2 3 v3 dump c p understand could altern flatten field b do group iter record call someudf appropri would 2 oper afaik p candid project googl summer code 2011 inform program find http nofollow http 
support pass bloom filter bloom udf p current bloom filter buildbloom store hdf abl use bloom udf time bloom filter reus delet end script also forc multipl dag pass scalar would simpl 
support express need way foreach indic rest field p common use case see person mani column datum want oper consid exampl store datum ten column user want perform cast one column div code panel 1px div codecont panelcont pre z foreach gener span int firstcol secondcol thridcol forthcol fifthcol sixthcol seventhcol eigthcol ninethcol tenthcol store z output p obvious get bad user column ideal could transform someth like div code panel 1px div codecont panelcont pre z foreach gener span int firstcol span span rest store z output 
udf abl indic file load distribut cach p current way udf load file distribut 
deep cast complex type p handl deep cast bag gt bag tupl gt tupl eg follow script produc desir result div code panel 1px div codecont panelcont pre load a0 bag tupl i0 span doubl b foreach gener bag tupl span int a0 dump b p result tupl still contain int insid tupl bag p http cast complex type take effect del fix case cast bytearray del gt take complex type includ inner type bag gt bag gt tupl still 
add abil load datum column famili hbasestorag p would nice load column column famili use short hand syntax like div preformat panel 1px div preformattedcont panelcont pre cpumetr load hbase use cpu p assum column cpu cpu cpu cpu cpu column p cpumetr would contain someth like div preformat panel 1px div preformattedcont panelcont pre rowkey cpu cpu cpu cpu 
add macro expans latin p product script grow longer long latin need integr standard program techniqu separ code share offer function modul propos add macro expans latin post http nofollow http p brief summari propos syntax exampl ul li macro definit p exist defin keyword expand allow definit macro p b syntax div code panel 1px div codecont panelcont pre defin lt name gt lt param gt return lt alia gt lt latin fragment gt p b exampl div code panel 1px div codecont panelcont pre defin sortkey return c b filter c order b sortkey ul li macro expans p b syntax div code panel 1px div codecont panelcont pre lt alias gt lt macro name gt lt param gt p b exampl use macro script div code panel 1px div codecont panelcont pre x load foo user address phone x user store bar p script expand follow latin statement div code panel 1px div codecont panelcont pre x load foo user address phone filter x order user store bar p b note p 1 alia macro visibl outsid prefix macro name suffix instanc id avoid namespac collis 2 macro expans complet replac function call recurs expans support ul li macro import p new import keyword use add macro defin anoth latin p b syntax div code panel 1px div codecont panelcont pre span import lt latin file name gt p b exampl div code panel 1px div codecont panelcont pre span import p b note macro name global namespac 
javascript support embed udf script languag p attach patch propos javascript implement embed udf script similar jython implement use rhino provid differ ul altern squar li output schema provid lt functionnam gt lt schema gt javascript annot decor function first class object li tupl convert object use input schema way around use output schema p attach patch final yet particular lack unit see transit closur exampl p see follow jira context http nofollow http http nofollow http 
type map p current map type untyp mean map valu alway bytearray ie unknown type http give error messag cogroup tupl key differ inner type del allow unknown type shuffl key somewhat reliev problem howev type map still benefici p 1 user make semant use map valu type current user need explicitli cast map valu ugli 2 though http give error messag cogroup tupl key differ inner type del allow unknown type shuffl key perform suffer raw compar unknown type instead need instanti valu object invok compar p propos syntax type map map span error 91 type 93 p type map use place untyp map could occur exampl load map span error 91 int 93 b foreach gener map span error 91 int 93 a0 map valu tupl b stream cat map int j chararray p map valu bag p maplookup type map result datatyp map load map span error 91 int 93 b foreach gener 0 key p schema b b int p behavior untyp map remain 
need special interfac penni inspector gadget p propos penni tool need access new logic plan order inject code dataflow modifi plan need abl hand back modifi plan execut p want open function gener user propos subclass pigserv new class mark limitedpriv penni class provid call pars latin script return logic plan one take logic plan execut 
enabl storefunc make intellig decis base job success failur p process use pig variou datum process compon integr feel storag func lack p awar job succeed creat problem storag func need upload result anoth system p db ftp anoth file system p look dbstorag piggybank http nofollow http see essenti mechan task follow p 1 creat recordwrit case open connect db 2 open 3 write record batch 4 execut commit rollback depend task p aproach work great task level work job level p certain task succeed job fail partial record go get upload p idea workaround p current workaround fairli ugli creat java wrapper launch job upload db job success approach work realli integr 
storag access layer p layer need provid high level datum access abstract tabular view datum hadoop could free user implement datum code layer also includ columnar storag format order provid fast datum project datum serial schema languag manag physic storag metadata eventu could also support predic pushdown perform improv initi layer could contrib project becom hadoop subproject later 
penni framework workflow instrument p penni framework instrument workflow rewrit script insert monitor point aka agent provid commun framework trigger collect event 
support effici merg join datum sourc nativ support point lookup join larg spars tabl p exist pig merg join follow limit 1 assum right side tabl must access sequenti record 2 perform well larg spars p current implement merg join introduc interfac indexableloadfunc loadfunc support abil seeknear give key read next record merg join physic oper call seeknear first key split effect elimin split first subsequ key find subsequ join find read sequenti record right tabl look match leav p method work well dens join tabl perform poorli larg spars tabl datum sourc support point lookup nativ hbase exampl p propos enhanc add new join type pig latin specifi pig script join type caus merg join oper call seeknear everi key rather first split 
add builtin udf build use bloom filter p bloom filter common way select limit set record move datum join heavi weight oper add udf support build use bloom 
p implement base alan implement book http nofollow http make minor chang 1 drop jackson featur requir sinc hadoop bundl jackson new featur fail run hadoop 2 use json format schema borrow dmitri schema implememt 3 bug 
need signatur evalfunc p gener uniqu signatur user use key retriev properti udfcontext need similar mechan 
support effici tupl schema know p tupl signific overhead due fact field tupl contain primit field int long etc possibl avoid overhead would result signific memori 
pigrc specifi default script cach p way specifi default statement help multipl user use interact 
integr hcat ddl command p would like run hcat ddl command insid script grunt use similar approach f sh p grunt gt hcat creat tabl p similar f sh plan add java api pigserv 
udf p possibl write udf rubi udf regist way python javascript 
support pluggabl pigprogressnotifcationlisten command line p would conveni abl implement tt pigprocessnotifcationlisten wire script jira support set listen constructor arg command perhap like p tt noformat mylisten foo bar bat tt noformat p tt mylisten take singl string constructor get pass tt foo bar bat 
easi udf conveni evalfunc p get abstract extens evalfunc make life easi person interest push say class p 3 class extend next class name ul li tt typedoutputevalfunc lt gt implement tt public schema outputschema schema input base gener type subclass provid common helper valid function increment counter good bad tupl datum pass use input work tupl size n li tt primitiveevalfunc lt gt helper valid allow abil subclass implement tt public exec input primit use input singl primit posit 0 li tt functionwrapperevalfunc wrap guava function implement http nofollow http allow udf use script like tt myfunct class implement tt function div preformat panel 1px div preformattedcont panelcont pre defin myudf myfunct 
support provid paramet python script p emb script python way get user pass paramet python though http need way deal param emb python del add capabl read param script python still would nice featur sort post process happen python scrip base 
support multipl input schema avrostorag p barebon patch avrostorag enabl support multipl input schema assumpt input consist avro file differ schema union flat record p simpl illustr exampl attach run follow follow 
conveni mock loader storer simplifi unit test script p test would look follow div code panel 1px div codecont panelcont pre pigserv pigserv span new pigserv tuplefactori tf data datum span foo span span b span c span load foo use span complex script test span store bar use iter lt tupl gt span bar assertequ span 0 assertequ span b 0 assertequ span c 0 
ppnl get notifi plan get execut p tt pigprogressnotificationlistn get notifi plan tt mroperplan get execut allow listen inspect plan idea expect execut flow propos add follow method ppnl interfac mark evolv div code panel 1px div codecont panelcont pre span public void initialplannotif mroperplan plan 
allow set arbitrari jobconf pair insid program p would use abl set arbitrari jobconf pair insid program front cogroup statement wonder whether simpl way add featur expand set command 
provid method measur time spend udf p debug slow job often use know whether time spend udf udf easi measur within framework let user option track 
add option pigstorag p recent add option pigstorag allow we add filenam record come return p often user want whole path sourc file propos add option 
stream provid conf set environ p hadoop stream convert jobconf properti environ variabl stream use featur stream 
grunt shortcut p featur aim provid shortcut frequent use command like illustr dump explain describ quit help etc featur inspir postgr psql shortcut tri implement simpl shortcut quit grunt shell use minim chang think featur help save mani keystrok user featur look use submit current patch review go ahead implement follow shortcut p lt alia gt illustr lt alia gt explain lt alia gt describ lt alia gt dump help p also use view inform store hcatalog similar way psql lt alia gt display tabl display metadata etc p except delimit abl use charact shortcut pleas let know 
output support recoveri hadoop p hadoop output committ option support recoveri handl applic master get restart fail attempt possibl support 
allow avrostorag store oper use schema specifi uri p attach patch make avrostorag accept flag store alia schema use store content alia content file uri refer must exist fit somewher schema flag specifi schema inlin string flag specifi schema appear datum 
allow prefix add uri pigunit test p run pigunit test use local file system use absolut path script test jail datum test use know 
introduc syntax abl easili refer previous defin relat p sometim feel like swim antlr particular featur hard add support syntax like div code panel 1px div codecont panelcont pre load thing x span int b foreach gener x c foreach gener x foreach gener x p patch though need make sure chang anyth need add 
hbasestorag support set timestamp field p current timestamp alway set current time millisecond option overrid propos configur set use second field timestamp 
allow default func configur p pigstorag use default specifi would use make 
piggybank function mimic claus sql p order test hive write udf mimic behavior sql claus thought would use 
allow use hive udf p would nice provid interoper hive wrap hive udf use hive udf p candid project googl summer code 2013 inform program find http nofollow http 
add assert keyword oper p assert oper use datum valid assert write script div code panel 1px div codecont panelcont pre load someth a0 span int a1 span int span assert a0 gt 0 cant neg span reason p script fail assert 
make work hbase p hbase chang api incompat way follow api tt hbasestorag use long avail ul li tt boolean li tt dataoutput p also addit hbase long avail one monolith archiv entir function break small piec tt tt 
add xml format explain mapreduc plan p mortar need easi way script map reduc plan add xml output format mapreduc plan make easi also add flag keep track store load origin script associ alia temporari gener 
default split destin p split statement well default destin eg div code panel 1px div codecont panelcont pre split x f1 lt 7 z f3 lt 6 f3 gt 6 otherwis other tupl f1 gt amp amp f2 amp amp p candid project googl summer code 2011 inform program find http nofollow http 
use hadoop local mode small job p use hadoop local mode small job mapper reduc mb 
provid storefunc loadfunc accumulo p accumulo code allow read write work make robust would like tri get includ avoid necess bundl addit jar p info current exist http nofollow http current code http nofollow http p 1 need translat maven build 2 need figur support accumulo build differ depend api 
abil disabl command oper p admin featur provid abil blacklist whitelist certain command oper expos could safe multiten environ exampl sh invok shell command set allow user chang config tremend use gener abil disabl would make safe platform goal allow administr abl control user script default behaviour would still filter appli command 
new logic optim rule constantcalcul p use logicexpressionsimplifi simplifi express also calcul constant express optim rule buggi disabl default http incorrect result filter filterlogicexpressionsimplifi optim turn del p howev need featur especi push sinc deal complex constant express like replac express constant actual push ye user may manual calcul rewrit queri even rewrit sometim possibl consid case user want push datetim predic user write todat udf sinc datetim p jira provid new rule constantcalcul much simpl much less error prone replac 
ship depend jar automat p user use need regist depend jar manual would much conveni provid mechan claim depend ship jar 
hbasestorag support delet marker p case write delet hbase would use preced delet oper http nofollow http think valid use case especi consid hbase delet realli write tombston marker 
